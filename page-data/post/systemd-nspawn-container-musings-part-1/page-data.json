{"componentChunkName":"component---src-templates-blog-post-js","path":"/post/systemd-nspawn-container-musings-part-1/","result":{"data":{"markdownRemark":{"html":"<h2>What is systemd-nspawn?</h2>\n<p><code>systemd</code> is known as INIT system, which is used in many unix and linux distributions. <code>systemd-nspawn</code> is available as a part of default systemd package and if it is not available, install the following packages:</p>\n<ul>\n<li>systemd-container (MAIN)</li>\n<li>bridge-utils (OPTIONAL - For managing networks)</li>\n</ul>\n<p><code>systemd-nspawn</code> can be used to run raw images or docker images without installing additional software tools and it is controlled by <code>systemd</code>, with the help of namespaces all the networks and logs are separated in our host itself. This post is not about what docker can and cannot do, it's more about how to use <code>systemd-nspawn</code> to achieve containerization without having to worry about extra tooling.</p>\n<p>I have seen many people calling this as a replacement for <code>chroot</code>, which is true and it can be much more than that is my opinion. Before, proceeding further, please make backup of your system, incase of issues. Though this is purely a precaution, we don't want to risk losing data.</p>\n<h2>Before we proceed:</h2>\n<ul>\n<li>HOST or host means your machine, the machine that you're using to create containers</li>\n<li>CONTAINER or container means the actual containers created using the host</li>\n</ul>\n<h2>Tools - we'll be using:</h2>\n<ul>\n<li>systemd-nspawn</li>\n<li>machinectl</li>\n<li>debootstrap (OPTIONAL - wants a fresh installation)</li>\n<li>cloud-init (OPTIONAL - only if you choose cloud based image)</li>\n</ul>\n<h2>Pick your favourite OS or Image:</h2>\n<p>I chose ubuntu, which is relevant to my usecase. Choose from <a href=\"http://cloud-images.ubuntu.com/\">Ubuntu Cloud Images</a>.</p>\n<ul>\n<li><a href=\"http://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-root.tar.gz\">Ubuntu Xenial Server - Generic</a></li>\n</ul>\n<p>Don't rush to download it, we will be doing it using <code>machinectl</code> command. You can run the following commands as <code>root</code> (if you're daring!)</p>\n<pre><code class=\"language-bash\"># machinectl pull-tar http://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-root.tar.gz xenial\n# machinectl pull-tar [LINK] [CONTAINER NAME]\n......PROGRESS NOTIFICATION.........\n</code></pre>\n<p>Poof! where did my image go? Don't worry, it's safe in <code>/var/lib/machines/xenial</code> directory. By default, all images pulled using machinectl goto that directory.</p>\n<h2>Power on your first specialised container:</h2>\n<pre><code class=\"language-bash\"># systemd-nspawn -D /var/lib/machines/alpine -U -M xenial\nSpawning container xenial on /var/lib/machines/xenial.\nPress ^] three times within 1s to kill container.\nSelected user namespace base 706150400 and range 65536.\nroot@xenial:~#\n</code></pre>\n<p>Anything you do from now on is inside the container and make sure you're not doing it on your actual machine.</p>\n<h2>Add a new user:</h2>\n<pre><code class=\"language-bash\">root@xenial:~# adduser test-user\n......Normal User addition steps...........\n</code></pre>\n<h2>Add instance name to hosts file:</h2>\n<pre><code class=\"language-bash\">root@xenial:~# echo \"127.0.0.1 xenial\" >> /etc/hosts\n# If this is not done, then we'll keep getting an error `unable to resolve hostname: xenial` when executing commands.\n</code></pre>\n<h2>Adding a default network interface inside the container (Optional)</h2>\n<p>If you don't want to complicate your container setup by adding separate network for the container, then you can skip and proceed to the usage part. By default, the container talks to the host through a <code>host0</code> network interface, we need to add it the interfaces to autostart, when the container boots.</p>\n<p>When we say network couple of things come into picture, </p>\n<ul>\n<li>private subnet or host network (for host network, skip this section)</li>\n<li>Wired Network or Wireless network in host</li>\n</ul>\n<h3>Bridged Network with a Wired Connection in host</h3>\n<ul>\n<li>\n<p>For a wired network, it is straight forward, you create a bridge network between your container's virtual network and the wired connection using <code>brctl</code> (bridge-utils) in your host machine</p>\n<pre><code class=\"language-bash\">$ brctl addbr virxen\n$ brctl show virxen\nbridge name     bridge id               STP enabled     interfaces\nvirxen           8000.000000000000       no\n$ brctl addif [host internet connected wired interface]\n</code></pre>\n</li>\n<li>\n<p>If you do have a <code>dhcp service</code> running in your container, then you can add this in your container's network interfaces, which automatically gets an ip assigned for this container.</p>\n<pre><code class=\"language-bash\"># systemd-nspawn -D /var/lib/machines/alpine -U -M xenial\nSpawning container xenial on /var/lib/machines/xenial.\nPress ^] three times within 1s to kill container.\nSelected user namespace base 706150400 and range 65536.\nroot@xenial:~# echo 'auto host0' >> /etc/network/interfaces\nroot@xenial:~# echo 'iface host0 inet dhcp' >> /etc/network/interfaces\n</code></pre>\n</li>\n<li>\n<p>Now create a file named <code>xenial.nspawn</code> or any other name you've created your container with the following contents:</p>\n<pre><code class=\"language-bash\">[Exec]\n# Writable bind mounts don't with user namespacing\nPrivateUsers=no\n[Network]\nVirtualEthernet=yes\nBridge=virxen\n</code></pre>\n</li>\n<li>Make a directory named <code>nspawn</code> in <code>/etc/systemd</code> directory</li>\n<li>Copy the above file to the recently created <code>nspawn</code> directory</li>\n</ul>\n<h3>Bridged Network with a Wireless Connnection in Host using NAT:</h3>\n<ul>\n<li>For a wireless connection in host, we cannot add the interface directly to the bridge, instead we need to use <code>NAT</code> using <code>iptables</code> in our host.</li>\n<li>Follow the first step in the <code>Bridged Network with a Wired Connection in host</code> to create a bridge.</li>\n<li>Since, I want to provide a static ip address to my bridge interface, I did the below steps.</li>\n<li>\n<p>If you have a properly configured dhcp service, you can make use of it.</p>\n<pre><code class=\"language-bash\">$ sudo ip addr add 192.168.30.1/24 brd + dev [your brigde name]\n# verify using the next command\n$ ip a\n...........Many other network interfaces................\n9: virxen: &#x3C;BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether f6:33:3c:bd:a8:40 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.30.1/24 brd 192.168.30.255 scope global virxen\n       valid_lft forever preferred_lft forever\n</code></pre>\n</li>\n<li>\n<p>For adding the NAT rules</p>\n<pre><code class=\"language-bash\">$ sudo iptables -t nat -A POSTROUTING -s 192.168.30.0/24 ! -d 192.168.30.0/24 \\\n> -o [Your Internet Connected Wireles Interface Name] -j MASQUERADE\n# Note: If you worry about security a lot, tweak the rule as per your requirement, as it a very generous rule\n# verify using the next command\n$ sudo iptables -L -t nat\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination        \nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination         \nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination         \nMASQUERADE  all  --  192.168.30.0/24     !192.168.30.0/24     \n</code></pre>\n</li>\n<li>\n<p>Also, we need to tell our iptables to accept packets from our bridge to our wireless network interface. This is essential for our dns resolvers to work, otherwise\ndns resolution will fail</p>\n<pre><code class=\"language-bash\">$ sudo iptables -A FORWARD -i virxen -o [your wireless interface name] -j ACCEPT\n# verify using the next command\n$ sudo iptables -L --verbose --line-numbers FORWARD\nChain FORWARD (policy DROP 0 packets, 0 bytes)\nnum   pkts bytes target     prot opt in     out     source               destination         \n.........................MANY OTHER NETWORK INTERFACES.................................\n10      27  1608 ACCEPT     all  --  virxen [Your wirelsess interface name]  anywhere             anywhere            \n</code></pre>\n</li>\n</ul>\n<blockquote>\n<p><strong>Note:</strong> If you're not comfortable with messing around networking, please skip the above steps and use a minimal <code>nspawn</code> file\nI'll explain later in the series and it will default to host network.\nIt will take some efforts to get a hang of configuring things correctly with networking.</p>\n</blockquote>\n<p>These network rules that we have configured using iptables, will not persist across reboots, so you would need to find your way to keep them safely across reboots. Let's cover the iptables rules persistence in the next section.</p>","frontmatter":{"title":"systemd-nspawn - Containerization - Part 1","date":"22 November, 2020"},"excerpt":"What is systemd-nspawn? systemd is known as INIT system, which is used in many unix and linux distributions. systemd-nspawn is available asâ€¦"}},"pageContext":{"slug":"/systemd-nspawn-container-musings-part-1/","prev":{"fields":{"slug":"/til-bookmarks-firefox-html-to-plain-file-and-manage-using-version-control/"},"frontmatter":{"published":true}},"next":{"fields":{"slug":"/systemd-nspawn-container-musings-part-2/"},"frontmatter":{"published":true}}}},"staticQueryHashes":["63159454"]}